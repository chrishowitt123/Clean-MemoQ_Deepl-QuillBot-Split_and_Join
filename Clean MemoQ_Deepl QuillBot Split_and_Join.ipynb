{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bbe1ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemoQ master and DeepL + Quill splits are of equal length!\n",
      "\n",
      "917 = Pre-filtered length\n",
      "790 = Post-filtered length\n",
      "\n",
      "\n",
      "Removed during filtering\n",
      "\n",
      "(+244) 226 434 549 / 927 442 844 / 912 034 779\n",
      "Telephone: (+244) 923 595 093 / 912 205 979\n",
      "Telephone: (+244) 222 704 400 /222 704 401\n",
      "http://www.facebook.com/holisticos.angola\n",
      "9F KDX Toyosu Grand Square 1-7-12\n",
      "(+244) 222 704 400 /222 704 401\n",
      "Website: http://www.rnt.co.ao\n",
      "http://www.holisticos.co.ao\n",
      "Telephone: (+813) 6372 5183\n",
      "Waste Management Plan4701\n",
      "Waste Management Plan5201\n",
      "Waste Management Plan4201\n",
      "Waste Management Plan4901\n",
      "Waste Management Plan1601\n",
      "Waste Management Plan5401\n",
      "Waste Management Plan5101\n",
      "Website: www.tepsco.co.jp\n",
      "Waste Management Plan5001\n",
      "Waste Management Plan201\n",
      "http://www.tepsco.co.jp\n",
      "Table of Contentsii01\n",
      "www.holisticos.co.ao\n",
      "Rua 60, Casa No. 559\n",
      "http://www.rnt.co.ao\n",
      "2022-01-19 00:00:00\n",
      "2021-12-13 00:00:00\n",
      "(+244) 226 434 549\n",
      "(+244) 927 442 844\n",
      "(+244) 912 034 779\n",
      "+244 923 41 01 86\n",
      "1502/150202/03\n",
      "4799693215\n",
      "5401156421\n",
      "EmptyCell\n",
      "160504/05\n",
      "E-mail: \n",
      "Website:\n",
      "08011/17\n",
      "2015.46\n",
      "E-mail:\n",
      "160117\n",
      "150103\n",
      "130701\n",
      "200135\n",
      "200129\n",
      "200108\n",
      "160606\n",
      "200202\n",
      "160103\n",
      "170204\n",
      "160708\n",
      "160107\n",
      "E-mail\n",
      "200306\n",
      "200303\n",
      "150102\n",
      "150101\n",
      "150107\n",
      "180104\n",
      "200121\n",
      "170904\n",
      "150104\n",
      "170106\n",
      "299-06\n",
      "130507\n",
      "160506\n",
      "180108\n",
      "200304\n",
      "150105\n",
      "180201\n",
      "150106\n",
      "200101\n",
      "200102\n",
      "80317\n",
      "1606\n",
      "1602\n",
      "1701\n",
      "1302\n",
      "1708\n",
      "1704\n",
      "V.2\n",
      "V.1\n",
      "17\n",
      "13\n",
      "15\n",
      "18\n",
      "20\n",
      "16\n",
      "P\n",
      "R\n",
      "Y\n",
      "8\n",
      "H\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\chris\\Documents\\Transgola\\Clients\\PROJECTS\\2022\\444240122_TM_HS\\Orignal\\MemoQ\") \n",
    "\n",
    "# choose language pairs\n",
    "source = \"English\"\n",
    "target = \"Portuguese\"\n",
    "\n",
    "df = pd.read_excel(r\"MemoQOut.xlsx\", names=[source, target])\n",
    "\n",
    "# make sure everything (dates, numbers etc.) are strings.\n",
    "df = df.astype('str')\n",
    "\n",
    "# remove white spaces at begining and end of string\n",
    "df[source] = df[source].apply(lambda x: x.strip())\n",
    "\n",
    "# create normalised column to filter on (lower)\n",
    "df[f'{source}_2'] = df[source].str.lower().str.rstrip(\":\")\n",
    "\n",
    "# subset performs operation on specified columns only (normalised column)\n",
    "df.drop_duplicates(subset=[f'{source}_2'], inplace=True, keep=\"first\")\n",
    "df.drop(columns = f'{source}_2', inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "# filter out unwanted tags\n",
    "\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    #.replace('nan','')\n",
    "    .replace(r'\\[[0-9+]\\]?','', regex = True)\n",
    "    .replace(r'\\[[0-9+]\\}?','', regex = True)\n",
    "    .replace(r'\\{[0-9+]\\]?','', regex = True)\n",
    "    .replace(r'\\}\\}?','', regex = True)\n",
    "    .replace(r'\\]?|\\[?','', regex = True)\n",
    "    .replace(\"•\", \"\", regex = True)\n",
    "    .replace(r'\\S+@\\S+', \"\" , regex = True) # email addresses\n",
    "    .replace(r\"(Table|Figure) [0-9]+:\", \"\", regex = True) \n",
    "    .replace(\"\", \"EmptyCell\")\n",
    "    \n",
    ")\n",
    "\n",
    "# create list containing pre-filtered elements\n",
    "preFiltered = df[source].tolist()\n",
    "\n",
    "# filter cells\n",
    "df = df[(df[source].str.contains(\"EmptyCell\")==False)]\n",
    "df = df[df[source].str.contains('[A-Za-z]')] \n",
    "df = df[df[source].str.len()>1]\n",
    "\n",
    "# filter out strings ending with numbers but keep anything relivant\n",
    "df = df[(~df[source].str.endswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"))) \n",
    "        & (~df[source].str.startswith((\"Website\", \"E-mail\", \"http:\", \"www.\")))\n",
    "        | (df[source].str.endswith((\"Cleaning) *1\", \"SARS-Cov-2\")))]\n",
    "\n",
    "# create list containing post-filtered elements\n",
    "postFiltered = df[source].tolist()\n",
    "\n",
    "# output cleaned (tags), dups removed, filtered version of MemoQ output\n",
    "df.to_excel('memoQOutClean.xlsx')\n",
    "\n",
    "# set character length for split\n",
    "splitThreshold = 90\n",
    "\n",
    "#define splits\n",
    "forQuill =df[(df[source].str.len()>=splitThreshold) | (df[source].str.contains(\",\")) | (df[source].str.contains(\"\\?\"))]\n",
    "forQuill =forQuill[(forQuill[target] == 'nan')]\n",
    "forQuill.to_excel('forQuill.xlsx', index=False)\n",
    "\n",
    "forDeepL =df[(df[source].str.len()<splitThreshold) & (~df[source].str.contains(\"\\?\")) & (~df[source].str.contains(\",\"))]\n",
    "forDeepL =forDeepL[(forDeepL[target] == 'nan')]\n",
    "forDeepL.to_excel('forDeepL.xlsx', index=False)\n",
    "\n",
    "# check that the cleaned output has the same amount of rows as the splits combined\n",
    "\n",
    "if len(df[source]) == len(forQuill[target]) + len(forDeepL[source]):\n",
    "    print(\"MemoQ master and DeepL + Quill splits are of equal length!\\n\")\n",
    "else:\n",
    "    print(\"MemoQ master and DeepL + Quill splits are NOT of equal length!\\n\")\n",
    "\n",
    "print(f\"{len(preFiltered)} = Pre-filtered length\")\n",
    "print(f\"{len(postFiltered)} = Post-filtered length\")\n",
    "print(\"\\n\")\n",
    "print(\"Removed during filtering\\n\")\n",
    "\n",
    "results = set(preFiltered) - set(postFiltered)\n",
    "for r in sorted(results,  key=len, reverse=True):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a5f83e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# forQuillDone & forDeepLDone are the translated versions of the splits (translation pairs)\n",
    "\n",
    "\n",
    "os.chdir(r\"C:\\Users\\chris\\Documents\\Transgola\\Clients\\PROJECTS\\2022\\437030122_TM_HS\\Translation\\MemoQ Out\") \n",
    "\n",
    "quilled = pd.read_excel('forQuillDone.xlsx',  names=[source, target])\n",
    "deepLed = pd.read_excel('forDeepLDone.xlsx',  names=[source, target])\n",
    "memoQClean = pd.read_excel('memoQOutClean.xlsx')\n",
    "\n",
    "frames = [quilled, deepLed]\n",
    "\n",
    "conDf = pd.concat(frames, names=[source, target])\n",
    "conDf.to_excel('conDF.xlsx')\n",
    "conEn = conDf[target].tolist()\n",
    "conPt = conDf[source].tolist()\n",
    "\n",
    "memEn = memoQClean[target].tolist()\n",
    "memPt = memoQClean[source].tolist()\n",
    "\n",
    "\n",
    "conDict = OrderedDict(zip(conPt, conEn))\n",
    "memoQCleanDict =  OrderedDict(zip(memPt, memEn))\n",
    "\n",
    "for k in memoQCleanDict:\n",
    "    if k in conDict:\n",
    "        memoQCleanDict[k] = conDict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7611701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrans = pd.DataFrame([memoQCleanDict]).T\n",
    "preTrans = preTrans.reset_index()\n",
    "preTrans.columns=[source, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c13cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrans.to_excel('preTrans.xlsx')\n",
    "\n",
    "enList = preTrans[source].tolist()\n",
    "ptList = preTrans[target].tolist()\n",
    "\n",
    "\n",
    "textfile = open(\"EN.txt\", \"w\")\n",
    "for element in enList:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()\n",
    "\n",
    "textfile = open(\"PT.txt\", \"w\")\n",
    "for element in ptList:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e8ea8212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1320"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11867 - 13187\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2aa79b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15840"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1320 * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60974e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
